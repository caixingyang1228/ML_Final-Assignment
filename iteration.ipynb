{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comments\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Toxic comments. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using `BinaryClassificationPerformance` v1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.03\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1 -- baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first iteration, we build the function for feature building and extraction on natural language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "        \n",
    "        \n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['myfeature'] =  toxic_data['comment_text'].str.split(' ').str.len() * toxic_data['comment_text'].str.count(\"\\.\");\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\",\"myfeature\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count  myfeature\n",
      "0          42           5        210\n",
      "1          18           2         36\n",
      "2          42           3        126\n",
      "3         112           3        336\n",
      "4          13           1         13\n",
      "5          12           1         12\n",
      "6           8           0          0\n",
      "7          21           2         42\n",
      "8          83           7        581\n",
      "9          12           0          0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131075)\n",
      "(159571, 131075)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131075)\n",
      "(31915, 131075)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 12)\n",
      "(31915, 12)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='toxiccomments_train.csv', my_random_seed=12345)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit (and tune) Various Models on both Training and Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 6454, 'TN': 56308, 'FP': 58362, 'FN': 6532, 'Accuracy': 0.4916494328507865, 'Precision': 0.09957417921500863, 'Recall': 0.49699676574772833, 'desc': 'ols_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1613, 'TN': 14108, 'FP': 14568, 'FN': 1626, 'Accuracy': 0.4925896913676954, 'Precision': 0.09968481552438045, 'Recall': 0.4979932077801791, 'desc': 'ols_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(\"training set:\", ols_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(\"test set:\",ols_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12912, 'TN': 114586, 'FP': 84, 'FN': 74, 'Accuracy': 0.9987622986776963, 'Precision': 0.9935364727608494, 'Recall': 0.9943015555213307, 'desc': 'svm_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2053, 'TN': 27137, 'FP': 1539, 'FN': 1186, 'Accuracy': 0.9146169512768291, 'Precision': 0.5715478841870824, 'Recall': 0.6338376041988268, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(\"training set:\", svm_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(\"test set:\",svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12919, 'TN': 114612, 'FP': 58, 'FN': 67, 'Accuracy': 0.9990208059158989, 'Precision': 0.995530554057178, 'Recall': 0.9948405975666101, 'desc': 'lgs_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2068, 'TN': 27141, 'FP': 1535, 'FN': 1171, 'Accuracy': 0.9152122826257246, 'Precision': 0.5739661393283375, 'Recall': 0.6384686631676443, 'desc': 'lgs_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(\"training set:\", lgs_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(\"test set:\",lgs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12721, 'TN': 103348, 'FP': 11322, 'FN': 265, 'Accuracy': 0.9092326251801717, 'Precision': 0.529093707108098, 'Recall': 0.9795934082858463, 'desc': 'nbs_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2097, 'TN': 23637, 'FP': 5039, 'FN': 1142, 'Accuracy': 0.8063293122356259, 'Precision': 0.2938621076233184, 'Recall': 0.6474220438406916, 'desc': 'nbs_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(\"training set:\", nbs_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(\"test set:\",nbs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12867, 'TN': 114558, 'FP': 112, 'FN': 119, 'Accuracy': 0.9981904493325813, 'Precision': 0.9913706757069112, 'Recall': 0.9908362852302479, 'desc': 'prc_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2055, 'TN': 27211, 'FP': 1465, 'FN': 1184, 'Accuracy': 0.9169982766724111, 'Precision': 0.5838068181818182, 'Recall': 0.6344550787280024, 'desc': 'prc_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(\"training set:\", prc_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(\"test set:\",prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 11748, 'TN': 114488, 'FP': 182, 'FN': 1238, 'Accuracy': 0.9888763552046124, 'Precision': 0.9847443419949706, 'Recall': 0.9046665639919914, 'desc': 'rdg_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1872, 'TN': 26589, 'FP': 2087, 'FN': 1367, 'Accuracy': 0.8917750274165753, 'Precision': 0.47284667845415507, 'Recall': 0.5779561593084285, 'desc': 'rdg_test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(\"training set:\", rdg_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(\"test set:\",rdg_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungang/Documents/my_measures.py:26: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 0, 'TN': 114670, 'FP': 0, 'FN': 12986, 'Accuracy': 0.8982734849909131, 'Precision': nan, 'Recall': 0.0, 'desc': 'rdf_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 0, 'TN': 28676, 'FP': 0, 'FN': 3239, 'Accuracy': 0.8985116716277612, 'Precision': nan, 'Recall': 0.0, 'desc': 'rdf_test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jungang/Documents/my_measures.py:26: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth = 3)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train).astype(np.int), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(\"training set:\",rdf_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "rdf_performance_test.compute_measures()\n",
    "print(\"test set:\",rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAArHElEQVR4nO3deXxV5Z3H8c+PJIAkgOzKjtSNsAQSBbGy1BWwoFXrQl3aWsZausyMFlpmClPXVsaiYx2HWqFSrIqKooJWLahYVIIsIgqCrKIYEBACaBJ+88c5CSHcnNzE3OQmfN+v133lLM8553cO4f7yPM85zzF3R0REpDwNajsAERFJbkoUIiISSYlCREQiKVGIiEgkJQoREYmkRCEiIpGUKKTeM7PrzGxhbccRxczeM7Mh1V1WpDooUUi1MrMNZrbfzPaa2admNt3MMsqUGWhm/zCzPWa228yeNbMeZco0M7MpZrYp3NfacL51guNfYGbXV6J8VzNzM0v9Osd190x3X1DdZWtC+G98a23HIYmjRCGJ8G13zwCygL7Ar4pXmNkZwN+BZ4D2QDdgOfCGmZ0QlmkIvAJkAhcAzYCBwA7g9Bo7i2rydZOISK1zd330qbYPsAE4p9T874HnS82/DtwfY7t5wMPh9PXANiCjEsd14GfAR8B24C6gQbjuOmBhqbIDgcXA7vDnwHD5bUARcADYC9wXx3E3hcfeG37OCI/3BvAH4HPgVqA78A+CZLcdmAkcG+u6AZOAx4GHgT3Ae0BOFcv2A5aG62YBjwG3lnMu3wBeDa/LduCxUutOAV4Kz2c18N1w+RigAPgqPP9na/t3UJ/q/6hGIQljZh2BYcDacL4JwZf0rBjFHwfODafPAV5w972VPOTFQA7Bl+Mo4AcxYmoJPA/cC7QC7gaeN7NW7j6BIJGNdfcMdx8bbvOcmY0v55iDwp/HhtssCuf7EySttgQJyIA7CGpRpwKdCL7kyzMSeBQ4FpgD3FfZsmHNbDYwHWgJ/I3gGpXnFoLaXgugI/A/4X7SCZLEI+H5XAncb2aZ7j6VIOn9Pjz/b0fsX+ooJQpJhKfNbA+wGfgMmBgub0nwO/dJjG0+AYr7H1qVU6Yiv3P3z919EzCF4AutrBHAh+4+w90L3f1vwAdAuV9w7n6hu99ZyVi2uvv/hMfY7+5r3f0ld//S3fMIEtTgiO0Xuvtcdy8CZgB9qlB2AJAK3OvuBe7+FPB2xH4KgC5Ae3c/4O7FNwBcCGxw92nh+bwDPAlcWsE1kHpCiUIS4SJ3bwoMIWiyKE4AO4GDwPExtjmeoLkDguaZWGUqsrnU9EaCv97Lah+uo0zZDlU4XryxYGZtzexRM/vYzL4A/sqh6xLLp6Wm9wGNI/o6yivbHvjY3UuP/HlYXGX8kqDm83Z4Z1VxjawL0N/MdhV/gNHAcRH7knpEiUISxt1fJWj2mBzO5wOLgMtiFP8uQQc2wMvA+WGTR2V0KjXdGdgao8xWgi8+ypT9uDjsSh6zvPJll98RLuvt7s2A7xF8KSfSJ0AHMyt9nE7lFXb3T939R+7eHvgXgualbxAkl1fd/dhSnwx3/3Hxpgk7A0kKShSSaFOAc80sK5wfD1xrZj8zs6Zm1iK8tfIM4L/CMjMIvpyeNLNTzKyBmbUys1+b2fCIY90c7q8T8HOCjtuy5gInmdlVZpZqZpcDPYDnwvXbgBMqcX55BLWkirZpStDZu8vMOgA3V+IYVbWIoHN+bHiuo4i4a8zMLgv7lSCo/Xm4/XME1+xqM0sLP6eZ2alh2cpeM6ljlCgkocL2+IeB/wznFwLnA98h+It3I8EttN909w/DMl8SdGh/QNCJ+gVB23pr4K2Iwz0DLAGWEXRY/zlGPDsI2tz/naCJ65fAhe5e3Ox1D3Cpme00s3sBzGyemf26nPPbR9BZ/UbYLDOgnNj+i6CTfXcY21MR51Et3P0rguv8Q2AXQS3mOeDLcjY5DXjLzPYSdIr/3N3Xu/se4DzgCoIa2afA74BG4XZ/BnqE5/90Ys5GapMd3nxZN5jZXg/u06+OfV0ErHH3VWWWZxF06s0tZ7uRQI+ynZxm1p6g81AdfTXIzBw40d3X1nYsyczM3gIecPdptR2L1B2qUcBFwGVmNrDM8iyCO2SOYGap7j4HeLn4r85i7r5VSUKShZkNNrPjwqana4HewAu1HZfULQl7YtTMHiKo4n/m7j1jrDeCav5wgjs1rgtvu4t3/88T3OvdEdhPkPSWAQ8R3D3zJ4Lb/U4maI5IIWh3/TXBQ2CdgQcI7kE3YIyZDSKoRr8J/AIoNLNhBO20GeHPtcBWM3sH+DfgUzPbQdARWxwP7t7ZzK4L99+E4IGr2e7+y3jPUaQanEzwjEoGsA641N2rcuuxHMUS1vQUfunuJXjaNlaiGA78lCBR9Afucff+ce77AMHTs8sI2n3nEzxodRzBw1xDgYYE99HPI2gHX0fQ1p1OUFPoAfyF4Iv/bIJklUfQgXcMwdOvPYGnCdrYnyR42GhHuP/B4X5SCNp8hxM80JRN8Ffbz8Pj/YagDf5Lgidav+nuUbcoiogklYQ1Pbn7awSP+5dnFEEScXd/EzjWzOK9d/4g0BxoR/AU6g6Cu2QKw8+XBB2lT4TzJxHckvkuwW1+BeF0V4Jk9hLwB3fPIuhsXE+QdJ4B/o/g1saGBMMgfAzcTpAg+hI8mTsUSCN4ZuBAGN/EsMwr7r7b3Q8Aqzjy1szDhIPMXRXndSi77T+rsp2ISJSEdmabWVfguXJqFM8BdxY//WlmrwDj3D03RtkxBGPKAK2yg/yTCjQmNfVLmjXL4MsvvyQ/P582bdpQUFBAy5Yt+eyzz9i7dy9NmzblpJNOYuvWrTRo0IDjjgueE1q6dCktWrSgqKiI9PR0jjvuOFavXk2DBg1IS0ujQYMG7N+/n1atWvHpp59SWFiIu5OWlkbjxo3Zv38/jRs3JjU1lc8//5z27duza9cu9u3bR+PGjWnVqhVfffUVnTt3BmDt2rW0a9eOpk2blnvN9uzZw7Zt2/jGN75xxDp35/Bb4kVE4rNkyZLt7t6mKtvW5qiWsb7xYmatcDyZqQBmOQ75QBvgv2nQ4HecfHJDmjdvzgsvvEDnzp352c9+BsDf//53Zs+eTWpqKrm5uUyaNImMjAxuuukmADIyMrjyyivZtGkTZ511FjfddBNDhgwhIyODU045hby8PFasWEHHjh059dRT2b59OykpKXz66ad06tSJt99+m+bNm7N9e3Bn5dixY3nmmWd46623MDMKCwsZPHgws2bN4tVXX2XkyJEUFRVRVFTEa6+9FjNhDBgwoCQpXXvttbRo0YLnn3+eAwcOkJ+fz5w5cxg1ahQ7d+6koKCAW2+9lVGjRpWcz969e1mwYAGTJk2idevWrFy5kuzsbP76178qyYgcxcys7IgE8UvkiIMETTsry1n3f8CVpeZXA8dXvM9sh4YOOHR3aOMZGRmemZnpKSkp3qhRI1+7dq1nZWV5WlqaAz59+nTfsWOHT5w40e+66y4vlp6e7gsXLvS2bdt6u3btfO3atT548GAfMWKET5s2zXNycrxr167esGFDb926tZ9yymBPSeni0MWbNv2lA960aVPv2bOnA37FFVd4//79HfDMzEy/4YYbvGXLlu7ufuGFF/oZZ5zh8+fP9z179nhBQYHHMn/+fB8xYkTJ/LRp07xDhw6+Y8cOd3cvKCjw3bt3u7t7Xl6ed+/e3Q8ePFhyPsX7aNasmW/evNmLiop8wIAB/vrrr8c8nogcHYBcr4Ojx84BrrHAAGC3x303xmqCATjPIS2tLeeddx7z5s3DzFiyZAndu3dn6dKlPPPMM2RlZXH33Xdz+eWXM2nSpJLaBMDevXs588wzef3112nbti2XXHIJt9xyC61btyYjI4PFixezfv16FixYQGpqC9asKaCo6GoA9uz5MdCe7t0H8e6773L22Wezc+dOGjduzCuvBCNRjBs3jvT0dHbt2sWZZ55JUVERK1asYNeuXaSmxl+ZO/fcc2nZsiUQJPZf//rX9O7dm3POOYePP/6Ybdu2HbHN6aefTseOHWnQoAFZWVls2LAh7uOJiJSWyNtj/0YwKFxrM9tC0LmbBuDuDxAMpTCc4K6jfcD3K3eEBjRs+AAnnDCEdevWcf755/OnP/2JzMzMkhLDhg1j2LBhFe7ppJNOYsWKFSXzZ5111mHrzzjjDBo1WsPBg8VLbiG4KaoFO3cGIz9ccMEFJc0+ZsbKlStLtjczxo8fz4gRI5g7dy4DBgzg5Zdf5pRTTonrTNPTDw15NHPmTPLy8liyZAlpaWl07dqVAwcOHLFNo0aNSqZTUlIoLCyM61giImUlLFG4e6whnkuvd+AnVd1/Sgo89BCMHr0grvK33XYbs2Yd/hqEyy67jJycHMaNG3fY8m7dujF79uzDlm3aFHu/sZY/9thjDB06lIULF9K8eXOaN2/OunXr6NWrF7169WLRokV88MEHMRNF06ZN2bNnT7nnsXv3btq2bUtaWhrz589n48aqNzuKiMSjzr2iMTsbcnO7AisrKnqYCRMm0L59e+65556SZbNmzWLr1q0sW7aswu07d4ZY38nhDU2HadGiBQMHDuSLL77goYceAmDKlCnMnz+flJQUevToUW5Np3fv3qSmptKnTx+uu+46WrRocdj60aNH8+1vf5ucnByysrLirpWIiFRVnRvrKScnx3Nzj7iDNuFmzoQxY2DfvkPLmjSBqVNh9OgaD0dEpFLMbIm751RlW431FKfRo4Ok0KULmAU/lSRE5GhQ55qeatPo0dWXGN59912uvvrqw5Y1atSIt96KGkVbRKTmKVHUkl69esXVNyIiUtvU9CQiIpGUKEREJJIShYiIRFKiEBGRSPUyUUyaNInJkydXertly5Yxd27MV2RH2rp1K5deqrefikj9VC8Shbtz8NBATFUWlSiixkpq3749TzzxxNc+vohIMqqzt8du2LCBYcOGMXToUBYtWsRFF13EI488QqdOnWjTpg3Z2dkALF68mB/+8Iekp6fzzW9+k3nz5h02YF+xr776it/85jfs37+fhQsX8qtf/Yr333+frVu3smHDBlq3bs3tt9/O1VdfTX5+PgD33XcfAwcOZMOGDVx44YWsXLmS6dOnM2fOHPbt28e6deu4+OKL+f3vf1+j10ZEpFpVdXzy2vo0bJjtZu4dOqx3M/NFixZ5bm6u9+zZ0/Pz83337t3evXv3kvdOZGZm+htvvOHu7uPGjfPMzMxyx2ufNm2a/+QnPymZnzhxovfr18/37dvn7u75+fm+f/9+d3dfs2aNZ2dnu7v7+vXrS/Y7bdo079atm+/atcv379/vnTt39k2bNpV7TBGRmsDXeB9FnatRfPVV8PPjj8GsC+vWDSAvbwoXX3wxTZo0AWDkyJEA7Nq1iz179jBw4EAArrrqKp577rlKHW/kyJEcc8wxABQUFDB27FiWLVtGSkoKa9asibnN2WefTfPmzQHo0aMHGzdupFOnTpU+VxGRZFCn+yjc05kwIZiO9ZpPr4YBD0u/C+IPf/gD7dq1Y/ny5eTm5vJVcdYqQ++CEJH6pE4nCgjeBzFo0CBmz57N/v372bNnD88++ywQDPfdtGlT3nzzTQAeffTRyH3F8y6I448/ngYNGjBjxgyKioqq70RERJJUnU8UnTtDv379uPzyy8nKyuKSSy457A11f/7znxkzZgxnnHEG7l7SJBTL0KFDWbVqFVlZWTz22GNHrL/xxhv5y1/+woABA1izZs1htQ0Rkfqqzr2PwizHIXgfRTzvg9i7dy8ZGRkA3HnnnXzyySeHvbxIRORo8HXeR1HnOrMbNoSCgqAmcdttFQ/7/fzzz3PHHXdQWFhIly5dmD59eo3EKSJSX9S5GkV1vOHuxRdfjOs92SIi9cXXqVEclYlCRORoo1ehiohIwihRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERKaKIwswvMbLWZrTWz8THWNzezZ81suZm9Z2bfT2Q8IiJSeQlLFGaWAvwRGAb0AK40sx5liv0EWOXufYAhwH+bWcNExSQiIpWXyBrF6cBad//I3b8CHgVGlSnjQFMzMyAD+BwoTGBMIiJSSYlMFB2AzaXmt4TLSrsPOBXYCrwL/NzdD5bdkZmNMbNcM8vNy8tLVLwiIhJDIhOFxVhW9r2r5wPLgPZAFnCfmTU7YiP3qe6e4+45bdq0qe44RUQkQiITxRagU6n5jgQ1h9K+DzzlgbXAeuCUBMYkIiKVlMhEsRg40cy6hR3UVwBzypTZBJwNYGbtgJOBjxIYk4iIVFJqonbs7oVmNhZ4EUgBHnL398zshnD9A8AtwHQze5egqWqcu29PVEwiIlJ5CUsUAO4+F5hbZtkDpaa3AuclMgYREfl69GS2iIhEUqIQEZFIShQiIhJJiUJERCIpUYiISCQlChERiaREISIikZQoREQkkhKFiIhEUqIQEZFIShQiIhJJiUJERCIpUYiISCQlChERiaREISIikZQoREQkkhKFiIhEiitRmNkxZnZyooMREZHkU2GiMLNvA8uAF8L5LDObk+C4REQkScRTo5gEnA7sAnD3ZUDXRAUkIiLJJZ5EUejuuxMeiYiIJKXUOMqsNLOrgBQzOxH4GfDPxIYlIiLJIp4axU+BTOBL4BFgN/DzRAYlIiLJI54axQh3nwBMKF5gZpcBsxIWlYiIJI14ahS/inOZiIjUQ+XWKMxsGDAc6GBm95Za1QwoTHRgIiKSHKKanrYCucBIYEmp5XuAf01kUCIikjzKTRTuvhxYbmaPuHtBDcYkIiJJJJ7O7K5mdgfQA2hcvNDdT0hYVCIikjTi6cyeBvwvQb/EUOBhYEYigxIRkeQRT6I4xt1fAczdN7r7JOBbiQ1LRESSRTxNTwfMrAHwoZmNBT4G2iY2LBERSRbx1Ch+ATQhGLojG/gecG0CYxIRkSQSWaMwsxTgu+5+M7AX+H6NRCUiIkkjskbh7kVAtplZVXZuZheY2WozW2tm48spM8TMlpnZe2b2alWOIyIiiRNPH8VS4BkzmwXkFy9096eiNgprI38EzgW2AIvNbI67rypV5ljgfuACd99kZur7EBFJMvEkipbADg6/08mByERB8LKjte7+EYCZPQqMAlaVKnMV8JS7bwJw98/ijFtERGpIhYnC3avaL9EB2FxqfgvQv0yZk4A0M1sANAXucfeHy+7IzMYAYwA6d+5cxXBERKQq4rnrqapi9Wt4mflUgjupRgDnA/9pZicdsZH7VHfPcfecNm3aVH+kIiJSrnianqpqC9Cp1HxHgoEGy5bZ7u75QL6ZvQb0AdYkMC4REamERNYoFgMnmlk3M2sIXAHMKVPmGeAsM0s1syYETVPvJzAmERGppAoThZm1M7M/m9m8cL6Hmf2wou3cvRAYC7xI8OX/uLu/Z2Y3mNkNYZn3gReAFcDbwIPuvrLqpyMiItXN3Mt2G5QpECSIacAEd+9jZqnAUnfvVRMBlpWTk+O5ubm1cWgRkTrLzJa4e05Vto2n6am1uz8OHISSmkJRVQ4mIiJ1TzyJIt/MWhHesWRmA4DdCY1KRESSRjx3Pf07QSd0dzN7A2gDXJrQqEREJGnE88DdEjMbDJxM8GzEar0aVUTk6BHPXU/LgV8CB9x9pZKEiMjRJZ4+ipEEr0F93MwWm9lNZqZxNEREjhIVJorw9ae/d/dsgkH8egPrEx6ZiIgkhbiG8DCzrsB3gcsJbo39ZQJjEhGRJFJhojCzt4A0YBZwWfGw4SIicnSIp0Zxrbt/kPBIREQkKZXbR2Fm3wsnh5vZv5X91FB8IvVORkZGpbe5/fbbq3Ss66+/nlWrVlVcUCRCVGd2evizaYxP5X/TRaTKyksU7s7BgwfL3e7BBx+kR48eiQpLjhLlJgp3/79w8mV3/6/SH+CVmglPpG67++676dmzJz179mTKlCmHrfvkk08YNGgQWVlZ9OzZk9dffz3mPsaPH8/+/fvJyspi9OjRbNiwgVNPPZUbb7yRfv36sXnzZn784x+Tk5NDZmYmEydOLNl2yJAhFA+imZGRwYQJE+jTpw8DBgxg27ZtCTtvqWfcPfIDvBPPspr6ZGdnu0hdkJub6z179vS9e/f6nj17vEePHv7OO+94enq6u7tPnjzZb731Vnd3Lyws9C+++KLcfRVv4+6+fv16NzNftGhRybIdO3aU7Gfw4MG+fPlyd3cfPHiwL1682N3dAZ8zZ467u998881+yy23VOPZSrIDcr2K37vldmab2RnAQKBNmT6JZkBK4lKXSN02cyZMmAAbNy6kefOLefrpdEaPhu985zuH1RpOO+00fvCDH1BQUMBFF11EVlZW3Mfo0qULAwYMKJl//PHHmTp1KoWFhXzyySesWrWK3r17H7ZNw4YNufDCCwHIzs7mpZde+nonKkeNqD6KhgR9Eakc3j/xBRoUUCSmmTNhzBjYuBHA2b07mJ8588iygwYN4rXXXqNDhw5cffXVPPzww3EfJz09vWR6/fr1TJ48mVdeeYUVK1YwYsQIDhw4cMQ2aWlpmAWvsk9JSaGwsLCypydHqXJrFO7+KvCqmU139401GJNInTVhAuzbVzw3CLiOffvG86tfOc2azWbGjBklZTdu3EiHDh340Y9+RH5+Pu+88w7XXHNNzP2mpaVRUFBAWlraEeu++OIL0tPTad68Odu2bWPevHkMGTKk2s9Njl5RTU9T3P0XwH1mdsRr8Nx9ZCIDE6mLNm0qPdcPuA44nc2b4Q9/uJ6+ffuWrF2wYAF33XUXaWlpZGRkRNYoxowZQ+/evenXrx+33XbbYev69OlD3759yczM5IQTTuDMM8+szlMSKf9VqGaW7YeGGD9CWOOocXoVqiSzrl2Lm50O16ULbNhQ09GIHJKQV6G6+5Lw56vFH2AFsLO2koRIsrvtNmjS5PBlTZoEy0XqqnjGelpAMNR4KrAMyDOzV91dT2eLlDF6dPBzwoSgGapz5yBJFC+vSP/+/fnyyy8PWzZjxgx69epVzZGKxK/cpqeSAmZL3b2vmV0PdHL3iWa2wt17R26YIGp6EhGpvIQ0PZWSambHEwwz/lxVDiIiInVXPInit8CLwDp3X2xmJwAfJjYsERFJFhX2Ubj7LIJ3URTPfwRcksigREQkeVRYozCzjmY228w+M7NtZvakmXWsieBERKT2xdP0NA2YA7QHOgDPhstEROQoEE+iaOPu09y9MPxMB9okOC4REUkS8SSK7Wb2PTNLCT/fA3YkOjAREUkO8SSKHxDcGvtp+Lk0XCYiIkeBeO562kTwZLaIiByF4rnr6QQze9bM8sI7n54Jn6UQEZGjQDxNT48AjwPHE9z5NAv4WyKDEhGR5BFPojB3n1Hqrqe/AtEDRImISL1RYR8FMN/MxgOPEiSIy4HnzawlgLt/nsD4RESklsWTKC4Pf/5LmeU/IEgc5fZXmNkFwD1ACvCgu99ZTrnTgDeBy939iThiEhGRGhLPXU/dqrJjM0sB/gicC2wBFpvZHHdfFaPc7wgGHhQRkSQTTx9FVZ0OrHX3j9z9K4Kmq1Exyv0UeBL4LIGxiIhIFSUyUXQANpea3xIuK2FmHYCLgQeidmRmY8ws18xy8/Lyqj1QEREpXyIThcVYVvZuqSnAOHcvitqRu0919xx3z2nTRsNMiYjUpHjemW3AaOAEd/+tmXUGjnP3tyvYdAvQqdR8R2BrmTI5wKPBIWgNDDezQnd/Os74RUQkweKpUdwPnAFcGc7vIeikrshi4EQz62ZmDYErCIYrL+Hu3dy9q7t3BZ4AblSSEBFJLvHcHtvf3fuZ2VIAd98ZfvFHcvdCMxtLcDdTCvCQu79nZjeE6yP7JUREJDnEkygKwltYHcDM2gAH49m5u88F5pZZFjNBuPt18exTRERqVjxNT/cCs4G2ZnYbsBC4PaFRiYhI0ojngbuZZrYEOJvgTqaL3P39hEcmIiJJIZ67njoD+wjelV2yLHxPhYiI1HPx9FE8T9A/YUBjoBuwGshMYFwiIpIk4ml66lV63sz6ceQAgSIiUk9V+slsd38HOC0BsYiISBKKp4/i30rNNgD6ARpwSUTkKBFPH0XTUtOFBH0WTyYmHBERSTaRiSJ80C7D3W+uoXhERCTJlNtHYWap4aiu/WowHhERSTJRNYq3CZLEMjObA8wC8otXuvtTCY5NRESSQDx9FC2BHcC3OPQ8hQNKFCIiR4GoRNE2vONpJYcSRLGyLyASEZF6KipRpAAZxPemOhERqaeiEsUn7v7bGotERESSUtST2bFqEiIicpSJShRn11gUIiKStMpNFO7+eU0GIiIiyanSgwKKiMjRRYlCREQiKVGIiEgkJQoREYmkRCEiIpGUKEREJJIShYiIRFKiEBGRSEoUIiISSYlCREQiKVGIiEgkJQoREYmkRCEiIpGUKEREJJIShYiIRFKiEBGRSAlNFGZ2gZmtNrO1ZjY+xvrRZrYi/PzTzPokMh4REam8hCUKM0sB/ggMA3oAV5pZjzLF1gOD3b03cAswNVHxiIhI1SSyRnE6sNbdP3L3r4BHgVGlC7j7P919Zzj7JtAxgfGIiEgVJDJRdAA2l5rfEi4rzw+BebFWmNkYM8s1s9y8vLxqDFFERCqSyERhMZZ5zIJmQwkSxbhY6919qrvnuHtOmzZtqjFEERGpSGoC970F6FRqviOwtWwhM+sNPAgMc/cdCYxHRESqIJE1isXAiWbWzcwaAlcAc0oXMLPOwFPA1e6+JoGxiIhIFSWsRuHuhWY2FngRSAEecvf3zOyGcP0DwG+AVsD9ZgZQ6O45iYpJREQqz9xjdhskrZycHM/Nza3tMERE6hQzW1LVP8T1ZLaIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCSSEoWIiERSohARkUhKFCIiEkmJQkREIilRiIhIJCUKERGJpEQhIiKRlChERCRSvUsUkyZNYvLkyQB88MEHZGVl0bdvX9atW3dE2V27dnH//fdX6TjDhw9n165dXydUEZE6oc4nCnfn4MGDMdc9/fTTjBo1iqVLl9K9e/cj1kcliqKiosjjzp07l2OPPbbS8YqI1DV1MlFs2LCBU089lRtvvJF+/fpxyy23cPLJJ3POOeewevVqIPginzJlCg8++CBDhw6NuZ/x48ezbt06srKyuPnmm1mwYAFDhw7lqquuolevXgBcdNFFZGdnk5mZydSpU0u27dq1K9u3by+J5Uc/+hGZmZmcd9557N+/P/EXQUSkprh7wj7ABcBqYC0wPsZ6A+4N168A+lW8z2zv0GG9m5kvWrTIc3NzvWfPnp6fn++7d+/27t27+1133eXu7hMnTiyZjmX9+vWemZlZMj9//nxv0qSJf/TRRyXLduzY4e7u+/bt88zMTN++fbu7u3fp0sXz8vJ8/fr1npKS4kuXLnV398suu8xnzJhR7jFFRGoDkOtV/C5PTVQCMrMU4I/AucAWYLGZzXH3VaWKDQNODD/9gf8Nf0b6+GMw68K6dQPIy5vCxRdfTJMmTQAYOXLk14r79NNPp1u3biXz9957L7NnzwZg8+bNfPjhh7Rq1eqwbbp160ZWVhYA2dnZbNiw4WvFICKSTBLZ9HQ6sNbdP3L3r4BHgVFlyowCHg4T3pvAsWZ2fDw7d09nwoRg2syqLej09PSS6QULFvDyyy+zaNEili9fTt++fTlw4MAR2zRq1KhkOiUlhcLCwmqLR0SktllQI0nAjs0uBS5w9+vD+auB/u4+tlSZ54A73X1hOP8KMM7dc8vsawwwJphrlQ3HE7RWZQJL3ge6Au8TNGX1APKAbUB7oCicjiUlLP9uON8UaBfuHOBYoHU43zgs+yGwB+gVHrMBQY3ovXCbduF+t1Z8lb621sD2GjhOXaBrcYiuxSG6Foec7O5Nq7JhwpqeCL60yyqbleIpg7tPBaYCmFku7LgUeM49t2e4bAJwDbAReARY5e6TzWwSsNfdJ5cbpNkjQG9gHvA8cJO7XxiuawQ8DXQgSArbgUnuvsDMNgDnABlBLJ4TbnMTkOHuk8o7ZnUxs9zi4x7tdC0O0bU4RNfikOC7s2oSmSi2AJ1KzXfkyL+y4ylzBHffAPQsNX8bcFuMcpPi2NdVZRYtKLXuS4J+lFjbdQ0nt5eJpdykJCJSFyWyj2IxcKKZdTOzhsAVwJwyZeYA11hgALDb3T9JYEwiIlJJCatRuHuhmY0FXiRos3/I3d8zsxvC9Q8Ac4HhBH0A+4Dvx7HrqRUXOZyZtQJeibHqbHffUdn9JZFKX4t6TNfiEF2LQ3QtDqnytUhYZ7aIiNQPdfLJbBERqTlKFCIiEilpE4WZXWBmq81srZmNj7HezOzecP0KM+tXG3HWhDiuxejwGqwws3+aWZ/aiLMmVHQtSpU7zcyKwud56qV4roWZDTGzZWb2npm9WtMx1pQ4/o80N7NnzWx5eC3i6Q+tc8zsITP7zMxWlrO+at+bVR37I5Efgs7vdcAJQENgOdCjTJnhBM8+GDAAeKu2467FazEQaBFODzuar0Wpcv8guFni0tqOuxZ/L44FVgGdw/m2tR13LV6LXwO/C6fbAJ8DDWs79gRci0FAP2BlOeur9L2ZrDWKhA7/UcdUeC3c/Z/uvjOcfZPgeZT6KJ7fC4CfAk8Cn9VkcDUsnmtxFfCUu28CcPf6ej3iuRYONLVgvJ8MgkRR78bacffXCM6tPFX63kzWRNEB2Fxqfku4rLJl6oPKnucPCf5iqI8qvBZm1gG4GHigBuOqDfH8XpwEtDCzBWa2xMyuqbHoalY81+I+4FSCB3rfBX7u7rFfZFO/Vel7M5FPZn8d1Tb8Rz0Q93ma2VCCRPHNhEZUe+K5FlMIxgsrqs7BIpNQPNciFcgGzgaOARaZ2ZvuvibRwdWweK7F+cAy4FtAd+AlM3vd3b9IcGzJpkrfm8maKBI2/EcdFNd5mllv4EFgmNfthwijxHMtcoBHwyTRGhhuZoXu/nSNRFhz4v0/st3d84F8M3sN6APUt0QRz7X4PsEApA6sNbP1wCnA2zUTYtKo0vdmsjY9afiPQyq8FmbWGXgKuLoe/rVYWoXXwt27uXtXD8biegK4sR4mCYjv/8gzwFlmlmpmTQje9fJ+DcdZE+K5FpsIalaYWTvgZOCjGo0yOVTpezMpaxSeuOE/6pw4r8VvgFbA/eFf0oVeD0fMjPNaHBXiuRbu/r6ZvUDw9siDwIPuHvO2yboszt+LW4DpZvYuQfPLOHevd8OPm9nfgCFAazPbAkwE0uDrfW9qCA8REYmUrE1PIiKSJJQoREQkkhKFiIhEUqIQEZFIShQiIhJJiUKSVjj667JSn64RZffWYGjlMrP2ZvZEOJ1lZsNLrRsZNeJtAmLpamZl3wkvUmm6PVaSlpntdfeM6i5bU8zsOiDH3ccm8Bip7h5zcDszGwLc5O4XJur4cnRQjULqDDPLMLNXzOwdM3vXzI4YOdbMjjez18IayEozOytcfp6ZLQq3nWVmRySVcPC8KRa802OlmZ0eLm9pZk+H4/e/GQ6XgpkNLlXbWWpmTcO/4leGTwj/Frg8XH+5mV1nZvdZ8G6EDWbWINxPEzPbbGZpZtbdzF4IB/F73cxOiRHnJDObamZ/Bx4Oj/l6eG7vmNnAsOidBE9mLzOzfzWzFDO7y8wWh+fyL9X0TyP1XW2Pn66PPuV9gCKCgdyWAbMJRhJoFq5rTfB0aXGteG/489+BCeF0CtA0LPsakB4uHwf8JsbxFgB/CqcHEY7pD/wPMDGc/hawLJx+FjgznM4I4+taarvrgPtK7b9knmB4jaHh9OUET00DvAKcGE73B/4RI85JwBLgmHC+CdA4nD4RyA2nhwDPldpuDPAf4XQjIBfoVtv/zvok/ycph/AQCe1396ziGTNLA243s0EEQ1J0ANoBn5baZjHwUFj2aXdfZmaDgR7AG+EQJw2BReUc828QjOtvZs3M7FiC0XgvCZf/w8xamVlz4A3gbjObSfDehy0W/4i1jxEkiPkEYxPdH9ZyBgKzSu2nUTnbz3H3/eF0GnCfmWURJNeTytnmPKC3HXrrX3OCxLI+3qDl6KREIXXJaIK3k2W7e4GZbQAaly4QfsEPAkYAM8zsLmAn8JK7XxnHMcp22jnlDM3s7nea2fMEY+e8aWbnAAfiPJc5wB1m1pJgKPB/AOnArtLJMUJ+qel/BbYRjAzbICIGA37q7i/GGaMIoD4KqVuaA5+FSWIo0KVsATPrEpb5E/BngtdCvgmcaWbfCMs0MbPy/uq+PCzzTYKRNXcTNFuNDpcPIRi6+wsz6+7u77r77wiaccr2J+whaPo6grvvJRji+h6C5qEiD96NsN7MLguPZRbf+8+bA5948CKeqwma3GId/0Xgx2FtCzM7yczS49i/HOVUo5C6ZCbwrJnlEvRbfBCjzBDgZjMrAPYC17h7XngH0t/MrLgp5z+I/V6GnWb2T6AZ8INw2SRgmpmtIBhx89pw+S/ChFVE8G7qeUDp10rOB8ab2TLgjhjHegyYFcZcbDTwv2b2HwRNSo8SvAM6yv3Ak2GCmc+h2sYKoNDMlgPTCZJSV+AdC9q28oCLKti3iG6PFSlmZgsIbifNre1YRJKJmp5ERCSSahQiIhJJNQoREYmkRCEiIpGUKEREJJIShYiIRFKiEBGRSP8PlO40r7CVP+oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [ols_performance_test, svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test, rdf_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 -- text tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this iteration, I focus on the text processing method. In some situations that text is very dirty, we need to reduce the negative influence that the dirty data lead to. In this dataset, there are a lot of situations we need to pay attention to: the difference of upper and lower cases, common words/ punctuation removal.\n",
    "\n",
    "After tidy the data, I use the same encoding method as the first iteration and also same models to check the improvement of data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing: lowcasing, common word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "lowcasing complete\n",
      "punctuation removal complete\n",
      "common words removal complete\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count  myfeature\n",
      "0          37           0          0\n",
      "1          16           0          0\n",
      "2          31           0          0\n",
      "3          74           0          0\n",
      "4           9           0          0\n",
      "5           8           0          0\n",
      "6           6           0          0\n",
      "7          14           0          0\n",
      "8          54           0          0\n",
      "9           6           0          0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131075)\n",
      "(159571, 131075)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131075)\n",
      "(31915, 131075)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 12)\n",
      "(31915, 12)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tidy the original text data by several rules\n",
    "def words_processing(fn, my_random_seed, test=False):\n",
    "    # read data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # lowcasing\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    print(\"lowcasing complete\")\n",
    "    \n",
    "    # remove punctuaton\n",
    "    toxic_data.comment_text = toxic_data.comment_text.str.replace(\"[^\\w\\s]\", \"\")\n",
    "    print(\"punctuation removal complete\")\n",
    "    \n",
    "    # remove common words\n",
    "    word_freq = list(pd.Series(\" \".join(toxic_data.comment_text).split()).value_counts()[:20].index)\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x for x in x.split() if x not in word_freq))\n",
    "    print(\"common words removal complete\")\n",
    "\n",
    "    \n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations2.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations2[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations2.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations2[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['myfeature'] =  toxic_data['comment_text'].str.split(' ').str.len() * toxic_data['comment_text'].str.count(\"\\.\");\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\",\"myfeature\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations2.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations2[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)\n",
    "\n",
    "#s = words_processing(fn='toxiccomments_train.csv', my_random_seed=100)\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations2 = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train2, X_test2, y_train2, y_test2, X_raw_train2, X_raw_test2 = words_processing(fn='toxiccomments_train.csv', my_random_seed=12345)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I run all models except random forest in the first iterations and name them xxx2 as the distinction to the models in the first iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 6653, 'TN': 56060, 'FP': 58610, 'FN': 6333, 'Accuracy': 0.4912655887698189, 'Precision': 0.10194137566461854, 'Recall': 0.5123209610349607, 'desc': 'ols_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1680, 'TN': 13891, 'FP': 14785, 'FN': 1559, 'Accuracy': 0.4878897070343099, 'Precision': 0.10203461888855148, 'Recall': 0.5186786045075641, 'desc': 'ols_test2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols2 = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols2.fit(X_train2, y_train2)\n",
    "\n",
    "ols_performance_train2 = BinaryClassificationPerformance(ols2.predict(X_train2), y_train2, 'ols_train2')\n",
    "ols_performance_train2.compute_measures()\n",
    "print(\"training set:\", ols_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "ols_performance_test2 = BinaryClassificationPerformance(ols2.predict(X_test2), y_test2, 'ols_test2')\n",
    "ols_performance_test2.compute_measures()\n",
    "print(\"test set:\",ols_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12914, 'TN': 114579, 'FP': 91, 'FN': 72, 'Accuracy': 0.9987231309143323, 'Precision': 0.9930026912725874, 'Recall': 0.9944555675342677, 'desc': 'svm_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2018, 'TN': 27076, 'FP': 1600, 'FN': 1221, 'Accuracy': 0.9116089613034624, 'Precision': 0.5577667219458264, 'Recall': 0.6230317999382525, 'desc': 'svm_test2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm2 = linear_model.SGDClassifier()\n",
    "svm2.fit(X_train2, y_train2)\n",
    "\n",
    "svm_performance_train2 = BinaryClassificationPerformance(svm2.predict(X_train2), y_train2, 'svm_train2')\n",
    "svm_performance_train2.compute_measures()\n",
    "print(\"training set:\", svm_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "svm_performance_test2 = BinaryClassificationPerformance(svm2.predict(X_test2), y_test2, 'svm_test2')\n",
    "svm_performance_test2.compute_measures()\n",
    "print(\"test set:\",svm_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12911, 'TN': 114625, 'FP': 45, 'FN': 75, 'Accuracy': 0.999059973679263, 'Precision': 0.9965267057733869, 'Recall': 0.9942245495148622, 'desc': 'lgs_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1998, 'TN': 27004, 'FP': 1672, 'FN': 1241, 'Accuracy': 0.9087263042456525, 'Precision': 0.5444141689373297, 'Recall': 0.6168570546464959, 'desc': 'lgs_test2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs2 = linear_model.SGDClassifier(loss='log')\n",
    "lgs2.fit(X_train2, y_train2)\n",
    "\n",
    "lgs_performance_train2 = BinaryClassificationPerformance(lgs2.predict(X_train2), y_train2, 'lgs_train2')\n",
    "lgs_performance_train2.compute_measures()\n",
    "print(\"training set:\", lgs_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "lgs_performance_test2 = BinaryClassificationPerformance(lgs2.predict(X_test2), y_test2, 'lgs_test2')\n",
    "lgs_performance_test2.compute_measures()\n",
    "print(\"test set:\",lgs_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12114, 'TN': 114507, 'FP': 163, 'FN': 872, 'Accuracy': 0.9918922729836436, 'Precision': 0.9867231408324509, 'Recall': 0.9328507623594641, 'desc': 'rdg_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1881, 'TN': 25516, 'FP': 3160, 'FN': 1358, 'Accuracy': 0.8584364718784271, 'Precision': 0.3731402499504067, 'Recall': 0.580734794689719, 'desc': 'rdg_test2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rdg2 = linear_model.RidgeClassifier()\n",
    "rdg2.fit(X_train2, y_train2)\n",
    "\n",
    "rdg_performance_train2 = BinaryClassificationPerformance(rdg2.predict(X_train2), y_train2, 'rdg_train2')\n",
    "rdg_performance_train2.compute_measures()\n",
    "print(\"training set:\",rdg_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "rdg_performance_test2 = BinaryClassificationPerformance(rdg2.predict(X_test2), y_test2, 'rdg_test2')\n",
    "rdg_performance_test2.compute_measures()\n",
    "print(\"test set:\",rdg_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 12909, 'TN': 114593, 'FP': 77, 'FN': 77, 'Accuracy': 0.9987936328883875, 'Precision': 0.9940705375019252, 'Recall': 0.9940705375019252, 'desc': 'prc_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 2014, 'TN': 27075, 'FP': 1601, 'FN': 1225, 'Accuracy': 0.9114522951590162, 'Precision': 0.5571230982019364, 'Recall': 0.6217968508799012, 'desc': 'prc_test2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc2 = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc2.fit(X_train2, y_train2)\n",
    "\n",
    "prc_performance_train2 = BinaryClassificationPerformance(prc2.predict(X_train2), y_train2, 'prc_train2')\n",
    "prc_performance_train2.compute_measures()\n",
    "print(\"training set:\",prc_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "prc_performance_test2 = BinaryClassificationPerformance(prc2.predict(X_test2), y_test2, 'prc_test2')\n",
    "prc_performance_test2.compute_measures()\n",
    "print(\"test set:\",prc_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can find the improvement is very little. I think this is due to the easy way to tidy the data. Then, I consider to apply different method to do the data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 3 -- dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in last iteration, the improvement of the model performance is little, I consider it caused by high dimension problem, that the feature is very sparse in high dimension. So dimension reduction techniques will be considered to cope with this problem. Here I only use SVD to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "lowcasing complete\n",
      "punctuation removal complete\n",
      "common words removal complete\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count  myfeature\n",
      "0          37           0          0\n",
      "1          16           0          0\n",
      "2          31           0          0\n",
      "3          74           0          0\n",
      "4           9           0          0\n",
      "5           8           0          0\n",
      "6           6           0          0\n",
      "7          14           0          0\n",
      "8          54           0          0\n",
      "9           6           0          0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131075)\n",
      "(159571, 512)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 512)\n",
      "(31915, 512)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 12)\n",
      "(31915, 12)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "def words_processing_svd(fn, my_random_seed, test=False):\n",
    "    # read data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # lowcasing\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    print(\"lowcasing complete\")\n",
    "    \n",
    "    # remove punctuaton\n",
    "    toxic_data.comment_text = toxic_data.comment_text.str.replace(\"[^\\w\\s]\", \"\")\n",
    "    print(\"punctuation removal complete\")\n",
    "\n",
    "    # remove common words\n",
    "    word_freq = list(pd.Series(\" \".join(toxic_data.comment_text).split()).value_counts()[:20].index)\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x for x in x.split() if x not in word_freq))\n",
    "    print(\"common words removal complete\")\n",
    "\n",
    "    \n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations3.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations3[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations3.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations3[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['myfeature'] =  toxic_data['comment_text'].str.split(' ').str.len() * toxic_data['comment_text'].str.count(\"\\.\");\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\",\"myfeature\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations3.append(sc)\n",
    "        \n",
    "        svd = decomposition.TruncatedSVD(512)\n",
    "        X = svd.fit_transform(X)\n",
    "        fitted_transformations3.append(svd)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        X = fitted_transformations3[2].transform(X_matrix)\n",
    "        X = fitted_transformations3[3].transform(X)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)\n",
    "    \n",
    "\n",
    "#s = words_processing(fn='toxiccomments_train.csv', my_random_seed=100)\n",
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations3 = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train3, X_test3, y_train3, y_test3, X_raw_train3, X_raw_test3 = words_processing_svd(fn='toxiccomments_train.csv', my_random_seed=100)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we only try to build the model of svm, ridge regression and perceptron to check the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12937, 'Neg': 114719, 'TP': 2887, 'TN': 111584, 'FP': 3135, 'FN': 10050, 'Accuracy': 0.8967146080090242, 'Precision': 0.47940883427432746, 'Recall': 0.22315838293267373, 'desc': 'svm_train3'} \n",
      "\n",
      "test set: {'Pos': 3288, 'Neg': 28627, 'TP': 673, 'TN': 27783, 'FP': 844, 'FN': 2615, 'Accuracy': 0.8916183612721291, 'Precision': 0.4436387607119314, 'Recall': 0.204683698296837, 'desc': 'svm_test3'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm3 = linear_model.SGDClassifier()\n",
    "svm3.fit(X_train3, y_train3)\n",
    "\n",
    "svm_performance_train3 = BinaryClassificationPerformance(svm3.predict(X_train3), y_train3, 'svm_train3')\n",
    "svm_performance_train3.compute_measures()\n",
    "print(\"training set:\", svm_performance_train3.performance_measures, \"\\n\")\n",
    "\n",
    "svm_performance_test3 = BinaryClassificationPerformance(svm3.predict(X_test3), y_test3, 'svm_test3')\n",
    "svm_performance_test3.compute_measures()\n",
    "print(\"test set:\", svm_performance_test3.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12937, 'Neg': 114719, 'TP': 45, 'TN': 114636, 'FP': 83, 'FN': 12892, 'Accuracy': 0.8983596540703139, 'Precision': 0.3515625, 'Recall': 0.003478395300301461, 'desc': 'rdg_train3'} \n",
      "\n",
      "test set: {'Pos': 3288, 'Neg': 28627, 'TP': 8, 'TN': 28586, 'FP': 41, 'FN': 3280, 'Accuracy': 0.8959423468588438, 'Precision': 0.16326530612244897, 'Recall': 0.0024330900243309003, 'desc': 'rdg_test3'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rdg3 = linear_model.RidgeClassifier()\n",
    "rdg3.fit(X_train3, y_train3)\n",
    "\n",
    "rdg_performance_train3 = BinaryClassificationPerformance(rdg3.predict(X_train3), y_train3, 'rdg_train3')\n",
    "rdg_performance_train3.compute_measures()\n",
    "print(\"training set:\",rdg_performance_train3.performance_measures, \"\\n\")\n",
    "\n",
    "rdg_performance_test3 = BinaryClassificationPerformance(rdg3.predict(X_test3), y_test3, 'rdg_test3')\n",
    "rdg_performance_test3.compute_measures()\n",
    "print(\"test set:\", rdg_performance_test3.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12937, 'Neg': 114719, 'TP': 4886, 'TN': 105110, 'FP': 9609, 'FN': 8051, 'Accuracy': 0.8616594597982077, 'Precision': 0.3370817523283891, 'Recall': 0.37767643193939865, 'desc': 'prc_train3'} \n",
      "\n",
      "test set: {'Pos': 3288, 'Neg': 28627, 'TP': 1181, 'TN': 26143, 'FP': 2484, 'FN': 2107, 'Accuracy': 0.8561491461695128, 'Precision': 0.32223738062755797, 'Recall': 0.35918491484184917, 'desc': 'prc_test3'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc3 = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc3.fit(X_train3, y_train3)\n",
    "\n",
    "prc_performance_train3 = BinaryClassificationPerformance(prc3.predict(X_train3), y_train3, 'prc_train3')\n",
    "prc_performance_train3.compute_measures()\n",
    "print(\"training set:\", prc_performance_train3.performance_measures, \"\\n\")\n",
    "\n",
    "prc_performance_test3 = BinaryClassificationPerformance(prc3.predict(X_test3), y_test3, 'prc_test3')\n",
    "prc_performance_test3.compute_measures()\n",
    "print(\"test set:\",prc_performance_test3.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show this dimension reduction method is not appropriate for this kind of dataset. So I think about different models to deal with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 4 -- xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of the third iteration, we may find the results show poor results compared with the first and second iterations. So I think this maybe due to poor model performance. Thus in this iteration, I will use a famous machine learning model: Xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 8914, 'TN': 114468, 'FP': 202, 'FN': 4072, 'Accuracy': 0.9665193958764179, 'Precision': 0.9778411584028083, 'Recall': 0.6864315416602494, 'desc': 'xgb_train'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1985, 'TN': 28479, 'FP': 197, 'FN': 1254, 'Accuracy': 0.954535484881717, 'Precision': 0.9097158570119157, 'Recall': 0.6128434702068539, 'desc': 'xgb_test'}\n"
     ]
    }
   ],
   "source": [
    "# Xgboost\n",
    "# Use the default settings using data in iteration 1\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_performance_train = BinaryClassificationPerformance(xgb.predict(X_train), y_train, 'xgb_train')\n",
    "xgb_performance_train.compute_measures()\n",
    "print(\"training set:\",xgb_performance_train.performance_measures, \"\\n\")\n",
    "\n",
    "xgb_performance_test = BinaryClassificationPerformance(xgb.predict(X_test), y_test, 'xgb_test')\n",
    "xgb_performance_test.compute_measures()\n",
    "print(\"test set:\", xgb_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: {'Pos': 12986, 'Neg': 114670, 'TP': 8468, 'TN': 114429, 'FP': 241, 'FN': 4518, 'Accuracy': 0.9627201228301059, 'Precision': 0.9723274773223103, 'Recall': 0.6520868627752965, 'desc': 'xgb_train2'} \n",
      "\n",
      "test set: {'Pos': 3239, 'Neg': 28676, 'TP': 1895, 'TN': 28492, 'FP': 184, 'FN': 1344, 'Accuracy': 0.9521228262572458, 'Precision': 0.9114959114959115, 'Recall': 0.5850571163939488, 'desc': 'xgb_test2'}\n"
     ]
    }
   ],
   "source": [
    "# Xgboost\n",
    "# Use the default settings using data in iteration 2\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb2 = XGBClassifier()\n",
    "xgb2.fit(X_train2, y_train2)\n",
    "\n",
    "xgb_performance_train2 = BinaryClassificationPerformance(xgb2.predict(X_train2), y_train2, 'xgb_train2')\n",
    "xgb_performance_train2.compute_measures()\n",
    "print(\"training set:\",xgb_performance_train2.performance_measures, \"\\n\")\n",
    "\n",
    "xgb_performance_test2 = BinaryClassificationPerformance(xgb2.predict(X_test2), y_test2, 'xgb_test2')\n",
    "xgb_performance_test2.compute_measures()\n",
    "print(\"test set:\", xgb_performance_test2.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [ols_performance_test, svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test, rdf_performance_test, \n",
    "       ols_performance_test2, svm_performance_test2, lgs_performance_test2, prc_performance_test2, rdg_performance_test2,\n",
    "        svm_performance_test3, rdg_performance_test3, prc_performance_test3,\n",
    "        xgb_performance_test,  xgb_performance_test2\n",
    "       ]\n",
    "\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score to compare performance of various models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score is a metric to measure the model performance combined with both precision and recall. The formula is  $f1{score} = 2* \\frac{precision * recall}{precision + recall}$. The range of f1 score is [0, 1], so we can use it to replace the accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ols_test : 0.16611740473738415\n",
      "svm_test : 0.6010832967354707\n",
      "lgs_test : 0.6045016077170418\n",
      "nbs_test : 0.40424096385542163\n",
      "prc_test : 0.6080781180648025\n",
      "rdg_test : 0.5201444845790497\n",
      "rdf_test : nan\n",
      "ols_test2 : 0.1705237515225335\n",
      "svm_test2 : 0.588595595741578\n",
      "lgs_test2 : 0.5783760312635693\n",
      "prc_test2 : 0.5876860227604319\n",
      "rdg_test2 : 0.4543478260869565\n",
      "svm_test3 : 0.28012486992715924\n",
      "rdg_test3 : 0.00479472580161822\n",
      "prc_test3 : 0.3397094779231986\n",
      "xgb_test : 0.7323372071573511\n",
      "xgb_test2 : 0.7126739375705152\n"
     ]
    }
   ],
   "source": [
    "# define f1\n",
    "def f1(performance_measures):\n",
    "    return 2 * performance_measures.performance_measures[\"Precision\"] * performance_measures.performance_measures[\"Recall\"] / (performance_measures.performance_measures[\"Precision\"] + performance_measures.performance_measures[\"Recall\"])\n",
    "\n",
    "\n",
    "fits = [ols_performance_test, svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test, rdf_performance_test, \n",
    "       ols_performance_test2, svm_performance_test2, lgs_performance_test2, prc_performance_test2, rdg_performance_test2, \n",
    "        svm_performance_test3, rdg_performance_test3, prc_performance_test3,\n",
    "        xgb_performance_test,  xgb_performance_test2\n",
    "       ]\n",
    "for fit in fits:\n",
    "    print(fit.desc, \":\", f1(fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at reviews based on their classification\n",
    "\n",
    "Let's say we decide that Xgboost is the best model on test set. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = xgb2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of false positives:\n",
      "58\n",
      "It was signed Moron - what part of that didn't you understand...\n",
      "* * * * * * * * * \n",
      "780\n",
      "\"BTW The Adversary on the wikipediareview website has  reputation for being extremely nasty and unpleasant about other wikipedians. Now Huldra has revealed this to be her, are you certain Huldra is exactly the sweet loving person she is to you. I have created a great deal really good content on here and this is how she and her moron wasters regard me. White cat  \n",
      "\n",
      "\"\n",
      "* * * * * * * * * \n",
      "5178\n",
      "\"\n",
      "\n",
      " TMI / Randall Thompson \n",
      "Hm, are you saying that your claims regarding his claims are more reputable due to your mentioning of him mentioning conspiracy?  I'd challenge your sanity if that would be the case, of course hoping it is not.  Many real stories sound unbelievable, and lots of crap is thoroughly \"\"sourced\"\" to fool people.  It takes close attention to even small discrepancies to tell reality apart from crap at times.  Good luck.   \"\n",
      "* * * * * * * * * \n",
      "5742\n",
      "Well, my mother always said that stupid comes in threes...all we need is one more, don't we? - User:Rattlerbrat\n",
      "* * * * * * * * * \n",
      "6659\n",
      "If she really has a problem with this stuff and what people are saying about her, then she should probably not act like such a stupid fool and commit all of these crimes!  She seems to me to be a VERY dangerous person and the Judge at her February 15, 2010, sentencing hearing said that she has showed NO REMORSE for her criminal activities.  I am willing to bet that she will soon be back before a court for violating her probation.\n",
      "* * * * * * * * * \n",
      "9201\n",
      "BARNSTAR \n",
      "as much as a stupid idea that is you should not have givin it to someone who blocked someone for vandelism if they didnt so i request you remove it and get me unblocked NOW.\n",
      "* * * * * * * * * \n",
      "13723\n",
      "\"\n",
      "I wish nothing to do with your \"\"community\"\" or bureaucratic processes. Good luck with your pathetic spam farm.  \"\n",
      "* * * * * * * * * \n",
      "14245\n",
      "\"\n",
      "I can dig up hundreds of sources of information that refer to African-Americans as \"\"Negroes\"\" or worse and the mentally challenged as \"\"idiots, imbeciles, morons\"\". The fact that a term has been used popularly in the past does not make it acceptable or scientific today. You will not find a source that states the ISR was a provisional government because the term is new and part of the evolving science of diplomacy and peace studies.  \"\n",
      "* * * * * * * * * \n",
      "16288\n",
      "efforts for the gay community keep it up man.\n",
      "* * * * * * * * * \n",
      "19990\n",
      "Missing sections \n",
      "\n",
      "As far as I can tell (& I admit to having drifted off now and then while reading it), this enormous article makes no mention at all of either political stereotyping (e.g. liberals are rich people who want to be loved by the people they shit on) or of the stereotypes of social class. Why?\n",
      "* * * * * * * * * \n",
      "20372\n",
      "RE: Bizarre Ride II \n",
      "\n",
      "Shit, I wrote that entire thing, man. It got turned down for FA, so I'm done with it. Good luck though.\n",
      "* * * * * * * * * \n",
      "21402\n",
      "\"Because of the growing irrelevance of Wikipedia and the Squeakbox crowd, I haven't bothered coming around here and this time I have read the incredible filth placed above by \"\"Hierarchypedia\"\" (interesting how none of you care to reveal your true identities.  The f___ word simply is not and never has been in my vocabulary.  I have NEVER posted the \"\"love that pot\"\" message.  That type of low class street talk comes from others!  I think retractions and apologies to myself are in order!\n",
      "\n",
      "\"\n",
      "* * * * * * * * * \n",
      "21984\n",
      "it is truly amazing how many ill-educated racists support Trump. Friends, if you would spend half the time pursuing an education and bettering yourself as you spend fawning over your Fuhrer and purchasing stupid hats with concealed racist slogans on them, your life would be much better, and you would not need to turn demagogues to feel better about your sorry lot in life. Chin up, friend!\n",
      "* * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(xgb_predictions)):\n",
    "    if (xgb_predictions[i] == 1):\n",
    "        if (X_raw_test.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_test.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 5 -- tune parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the most powerful tools, I consider using cross-validation to tune the parameters of xgboost to achieve the best performance. Since the model training will cost a lot, we just use 2-folder to select the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "lowcasing complete\n",
      "punctuation removal complete\n",
      "stopwords removal complete\n",
      "common words removal complete\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count  myfeature\n",
      "0          22           0          0\n",
      "1          12           0          0\n",
      "2          18           0          0\n",
      "3          43           0          0\n",
      "4           5           0          0\n",
      "5           4           0          0\n",
      "6           4           0          0\n",
      "7           5           0          0\n",
      "8          33           0          0\n",
      "9           4           0          0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131075)\n",
      "(159571, 131075)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131075)\n",
      "(31915, 131075)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 12)\n",
      "(31915, 12)\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_validate, validation_curve\n",
    "\n",
    "# only return the preprocessing data before train_test_split\n",
    "def words_processing_cv(fn, my_random_seed):\n",
    "    # read data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    \n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "    toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    \n",
    "    print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "    print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # lowcasing\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    print(\"lowcasing complete\")\n",
    "    \n",
    "    # remove punctuaton\n",
    "    toxic_data.comment_text = toxic_data.comment_text.str.replace(\"[^\\w\\s]\", \"\")\n",
    "    print(\"punctuation removal complete\")\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop = stopwords.words(\"english\")\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    print(\"stopwords removal complete\")\n",
    "    \n",
    "    # remove common words\n",
    "    word_freq = list(pd.Series(\" \".join(toxic_data.comment_text).split()).value_counts()[:20].index)\n",
    "    toxic_data.comment_text = toxic_data.comment_text.apply(lambda x: \" \".join(x for x in x.split() if x not in word_freq))\n",
    "    print(\"common words removal complete\")\n",
    "\n",
    "    \n",
    "   \n",
    "    hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "    X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "    print(\"Shape of HashingVectorizer X:\")\n",
    "    print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "    transformer = TfidfTransformer()\n",
    "    X_tfidf = transformer.fit_transform(X_hv)\n",
    "    \n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "    toxic_data['myfeature'] =  toxic_data['comment_text'].str.split(' ').str.len() * toxic_data['comment_text'].str.count(\"\\.\");\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\",\"myfeature\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    \n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    X = sc.fit_transform(X_matrix)\n",
    "    print(X.shape)\n",
    "    y = toxic_data['any_toxic']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    \n",
    "    print(\"Shape of X_train and X_test:\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(\"Shape of y_train and y_test:\")\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "    print(X_raw_train.shape)\n",
    "    print(X_raw_test.shape)\n",
    "    print('SUCCESS!')\n",
    "    return(X, y)\n",
    "    \n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X,y = words_processing_cv(fn='toxiccomments_train.csv', my_random_seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score: [0.71213829 0.71342383 0.69966254 0.7192846  0.71689077]\n"
     ]
    }
   ],
   "source": [
    "# cv check result\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "print('test_score:', cross_val_score(xgb2, X, y, cv=cv, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.663\n",
      "Best parameters set:\n",
      "\tlearning_rate: 0.1\n",
      "\tmax_depth: 10\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "parameters = {\n",
    "    'max_depth': [5, 10],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gsearch = GridSearchCV(xgb2, param_grid=parameters, scoring='f1', cv=2)\n",
    "gsearch.fit(X, y)\n",
    "print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model -- Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(**{\"learning_rate\":0.1, \"max_depth\":10})\n",
    "xgb.fit(X_train, y_train)\n",
    "data_process_method = process_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we do not choose the data_process_method as the method in iteration 2? \n",
    "##### In iteration 2, we do some data cleaning: lowcasing, common words removal, but the result shows poorer performance than the original one. This is because some toxic text is spelled by upper case and wrote in inofficial way. These non-normal patterns will become features to identify them. This is the reason why data cleaning shows negative results to the classification in toxic text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count  myfeature\n",
      "0          72          10        720\n",
      "1          13           1         13\n",
      "2          16           0          0\n",
      "3          38           3        114\n",
      "4           7           1          7\n",
      "5          16           2         32\n",
      "6          31           4        124\n",
      "7           6           1          6\n",
      "8         109           9        981\n",
      "9          41           0          0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 131075)\n",
      "(153164, 131075)\n",
      "Shape of X_test for submission:\n",
      "(153164, 131075)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164):  153164\n"
     ]
    }
   ],
   "source": [
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = data_process_method(fn='toxiccomments_test.csv', my_random_seed=12345, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \", X_test_submission.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the xgboost model fit, which is in the `xgb` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15019195111122718\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = xgb.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>myfeature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   word_count  punc_count  myfeature  \n",
       "0          72          10        720  \n",
       "1          13           1         13  \n",
       "2          16           0          0  \n",
       "3          38           3        114  \n",
       "4           7           1          7  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46       False\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('toxiccomments_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
